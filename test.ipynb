{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c32a9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CNN_musical.CNN_musical import ModeloCNN, fit\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb83a47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b08284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import CNN_musical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff050a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# data_dir = \"../data/spectrograms\"\n",
    "data_dir = \"data/MelSpectrograms/\"\n",
    "\n",
    "#load the train and test data\n",
    "dataset = ImageFolder(data_dir,transform = transforms.Compose([\n",
    "    transforms.Resize((150,150)),transforms.ToTensor()\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20cdb41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No ejectutar si vamos a cargar el modelo\n",
    "num_epochs = 7\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 0.001\n",
    "\n",
    "model = ModeloCNN(device)\n",
    "#fitting the model on training data and record the result after each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e916aa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1821bd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Train Data : 3216\n",
      "Length of Validation Data : 580\n",
      "Length of Test Data : 300\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "batch_size = 32\n",
    "val_size = 580\n",
    "test_size = 300\n",
    "train_size = len(dataset) - (val_size + test_size)\n",
    "\n",
    "train_data,val_data,test_data = random_split(dataset,[train_size,val_size,test_size])\n",
    "print(f\"Length of Train Data : {len(train_data)}\")\n",
    "print(f\"Length of Validation Data : {len(val_data)}\")\n",
    "print(f\"Length of Test Data : {len(test_data)}\")\n",
    "\n",
    "\n",
    "#load the train and validation into batches.\n",
    "train_dl = DataLoader(train_data, batch_size, shuffle = True, num_workers = 4, pin_memory = True)\n",
    "val_dl = DataLoader(val_data, batch_size*2, num_workers = 4, pin_memory = True)\n",
    "test_dl = DataLoader(test_data, batch_size, shuffle = True, num_workers = 4, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c27a9342",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'librosa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-56c009bbf11d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseparar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./datos_nuevos/Guitarra1.wav\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"datos_nuevos/prueba/\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\GitHub\\AudioClassificationModel\\utils\\utils.py\u001b[0m in \u001b[0;36mseparar\u001b[1;34m(audio_path, save_path, window_duration)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0maudio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAmplitudeToDB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[0maudio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maudio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m             \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'magma'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m             \u001b[0mnombre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msave_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".png\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnombre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbox_inches\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tight'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'librosa' is not defined"
     ]
    }
   ],
   "source": [
    "utils.separar(\"./datos_nuevos/Guitarra1.wav\", \"datos_nuevos/prueba/\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd63241",
   "metadata": {},
   "source": [
    "# Cargar el modelo y predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b610520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargarModelo(ruta, device):\n",
    "    model = ModeloCNN(device)\n",
    "    model.load_state_dict(torch.load(ruta, map_location=device))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "192eb101",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = \"../trainedModelNoHistory.pth\"\n",
    "device = torch.device('cpu')\n",
    "\n",
    "model = cargarModelo(ruta, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94571ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_predict(model, input):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(input)\n",
    "        predicted_index = predictions[0].argmax(0)\n",
    "    return predicted_index.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a2bdbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "def predict(model, data_dir, device):\n",
    "    dataset = ImageFolder(data_dir,transform = transforms.Compose([\n",
    "    transforms.Resize((150,150)),transforms.ToTensor()\n",
    "    ]))\n",
    "    data=DataLoader(dataset, 1, num_workers = 4, pin_memory = True)\n",
    "\n",
    "    predicciones = []\n",
    "    for batch in data:\n",
    "        indicePredicho=single_predict(model,batch[0].to(device))\n",
    "        predicciones.append(indicePredicho)\n",
    "    \n",
    "    return predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1239b0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common(predicciones):\n",
    "    return max(set(predicciones), key=predicciones.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1d06488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bass\n"
     ]
    }
   ],
   "source": [
    "instrumentos = ['bass', 'brass', 'flute', 'guitar', 'keyboard', 'mallet', 'organ', 'reed', 'string', 'vocal']\n",
    "\n",
    "ruta = \"./pruebas/\"\n",
    "\n",
    "predicciones = predict(model, ruta, device)\n",
    "prediccionFinal = most_common(predicciones)\n",
    "\n",
    "print(instrumentos[prediccionFinal])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
