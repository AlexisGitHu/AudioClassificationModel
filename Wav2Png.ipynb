{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f1732b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import scipy.io.wavfile\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchaudio\n",
    "import sys\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3ec384",
   "metadata": {},
   "source": [
    "# Creación y guardado de espectrogramas \n",
    "La función plot_specgram crea espectrogramas a partir de:\n",
    "    \n",
    "    -waveform: tensor de torachaudio\n",
    "    -sample_rate: entero\n",
    "    -title: str para el nombre del archivo\n",
    "    -save: boolean para guardar o no el archivo, por defecto true\n",
    "    -xlim: real para limitar el dominio (eje temporal), por defecto sin limitaciones\n",
    "    \n",
    "Además guarda el resultado en formato png en la ruta \"./nsynth-test/spectrograms/\". Elimina los ejes y la información de los ejes, para quedarse exclusivamente con la imagen.\n",
    "#### Produce imágenes en formato png de 352x235 pixeles\n",
    "\n",
    "### Consideraciones\n",
    "Dado que se pierde la referencia de la duración de la muestra, a la hora de ponerlo en práctica con muestras de más de 4 segundos, sería necesario dividirlas en fracciones de 4 segundos para estudiarlas.\n",
    "\n",
    "### PROBLEMA!!!\n",
    "Para los instrumentos capaces de producir exactamente cero ruido (generalmente los sintéticos o aquellos en los que la muestra dura menos de 4 segundos), produce franjas blancas en el intervalo de silencio. Esto no es muy realista sabiendo que las muestras reales tendrían ruido ambiente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ab7de22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_specgram(waveform, sample_rate, title, save=True, xlim=None):\n",
    "    waveform = waveform.numpy()\n",
    "\n",
    "    num_channels, num_frames = waveform.shape\n",
    "    time_axis = torch.arange(0, num_frames) / sample_rate\n",
    "\n",
    "    figure, axes = plt.subplots(num_channels, 1)\n",
    "    if num_channels == 1:\n",
    "        axes = [axes]\n",
    "    for c in range(num_channels):\n",
    "        axes[c].specgram(waveform[c], Fs=sample_rate)\n",
    "        if num_channels > 1:\n",
    "            axes[c].set_ylabel(f'Channel {c+1}')\n",
    "        if xlim:\n",
    "            axes[c].set_xlim(xlim)\n",
    "    ax = plt.gca()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    plt.savefig(\"./nsynth-test/spectrograms/\"+title+\".png\", bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c9413f",
   "metadata": {},
   "source": [
    "# Transformación de .wav a .png\n",
    "Usando la funcion anterior transforma el contenido de \"./nsynth-test/audio/\", registrado en \"nsynth-test/examples.json\", y crea un diccionario que mapea el nombre SIN EXTENSION del archivo y la familia de instrumentos a la que pertenece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9bb794f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"nsynth-test/examples.json\", \"r\") as f:\n",
    "    datos = json.loads(f.read())\n",
    "\n",
    "leyenda = {}\n",
    "for dato in datos:\n",
    "    waveform, sample_rate = torchaudio.load(\"./nsynth-test/audio/\"+dato+\".wav\")\n",
    "    plot_specgram(waveform, sample_rate, dato)\n",
    "    leyenda[dato] = datos[dato][\"instrument_family_str\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af612624",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('leyenda.json', 'w')\n",
    "f.write(json.dumps(leyenda))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47ce3ad",
   "metadata": {},
   "source": [
    "# Revisar muestras como bass_synthtic_068-107-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53703a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"./nsynth-test/audio/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39414c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform, sample_rate = torchaudio.load(\"./nsynth-test/audio/bass_synthtic_068-107-100.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979cf223",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_specgram(waveform, sample_rate, title =\"bass_synthtic_068-107-100\", save= False )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
